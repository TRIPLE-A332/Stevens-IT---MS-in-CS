{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "159df3e1-8bc8-403a-bb40-eeff2c151fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((414, 8),\n",
       "    No  X1 transaction date  X2 house age  \\\n",
       " 0   1             2012.917          32.0   \n",
       " 1   2             2012.917          19.5   \n",
       " 2   3             2013.583          13.3   \n",
       " 3   4             2013.500          13.3   \n",
       " 4   5             2012.833           5.0   \n",
       " \n",
       "    X3 distance to the nearest MRT station  X4 number of convenience stores  \\\n",
       " 0                                84.87882                               10   \n",
       " 1                               306.59470                                9   \n",
       " 2                               561.98450                                5   \n",
       " 3                               561.98450                                5   \n",
       " 4                               390.56840                                5   \n",
       " \n",
       "    X5 latitude  X6 longitude  Y house price of unit area  \n",
       " 0     24.98298     121.54024                        37.9  \n",
       " 1     24.98034     121.53951                        42.2  \n",
       " 2     24.98746     121.54391                        47.3  \n",
       " 3     24.98746     121.54391                        54.8  \n",
       " 4     24.97937     121.54245                        43.1  )"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "inputfile=\"Realestate.csv\"\n",
    "df=pd.read_csv(inputfile)\n",
    "df.shape, df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0441ee7c-c296-4d8f-ac5b-759c95df0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step b: Standardize the data using mean and standard deviation\n",
    "features = df.drop(columns=[\"No\", \"Y house price of unit area\"])  # Exclude 'No' and target variable\n",
    "target = df[\"Y house price of unit area\"]\n",
    "\n",
    "standardized_features = (features - features.mean()) / features.std()\n",
    "standardized_target = (target - target.mean()) / target.std()\n",
    "\n",
    "standardized_data = pd.concat([standardized_features, standardized_target.rename(\"Y_std\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c52a15b2-f355-4b94-aafe-03963db10493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step c: RMSE (Scikit-learn): 0.6455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Separate features and target\n",
    "X = standardized_features.values\n",
    "y = standardized_target.values\n",
    "\n",
    "# Initialize and fit the Scikit-learn Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict and calculate RMSE\n",
    "y_pred = model.predict(X)\n",
    "rmse_sklearn = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print(f\"Step c: RMSE (Scikit-learn): {rmse_sklearn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50e32e25-ca40-4716-92d6-9d6cb05f6875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step d: RMSE (Gradient Descent): 0.6455, Learning Rate: 0.01, Iterations: 1000\n"
     ]
    }
   ],
   "source": [
    "class LinearRegressionGD:\n",
    "    def __init__(self, learning_rate, iterations):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.m, self.n = X.shape\n",
    "        self.W = np.zeros(self.n)\n",
    "        self.b = 0\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            self.update_weights(X, y)\n",
    "\n",
    "    def update_weights(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        dW = -(2 / self.m) * np.dot(X.T, (y - y_pred))\n",
    "        db = -(2 / self.m) * np.sum(y - y_pred)\n",
    "\n",
    "        self.W -= self.learning_rate * dW\n",
    "        self.b -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.W) + self.b\n",
    "\n",
    "# Tune learning rate and iteration count\n",
    "best_eta = 0.01\n",
    "best_iterations = 1000\n",
    "model_gd = LinearRegressionGD(learning_rate=best_eta, iterations=best_iterations)\n",
    "model_gd.fit(X, y)\n",
    "\n",
    "# Predict and calculate RMSE\n",
    "y_pred_gd = model_gd.predict(X)\n",
    "rmse_gd = np.sqrt(mean_squared_error(y, y_pred_gd))\n",
    "print(f\"Step d: RMSE (Gradient Descent): {rmse_gd:.4f}, Learning Rate: {best_eta}, Iterations: {best_iterations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48a3b354-25b6-41e6-9e57-f04aae423c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step e: RMSE (Stochastic Gradient Descent): 0.6613\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class LinearRegressionSGD:\n",
    "    def __init__(self, learning_rate, iterations):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.m, self.n = X.shape\n",
    "        self.W = np.zeros(self.n)\n",
    "        self.b = 0\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            # Perform stochastic gradient descent (one random sample per update)\n",
    "            idx = random.randint(0, self.m - 1)  # Select a random index\n",
    "            X_i = X[idx].reshape(1, -1)  # Single sample\n",
    "            y_i = y[idx]  # Corresponding target\n",
    "            self.update_weights(X_i, y_i)\n",
    "\n",
    "    def update_weights(self, X_i, y_i):\n",
    "        y_pred = self.predict(X_i)\n",
    "        dW = -2 * X_i.T.dot(y_i - y_pred)\n",
    "        db = -2 * (y_i - y_pred)\n",
    "\n",
    "        self.W -= self.learning_rate * dW.flatten()\n",
    "        self.b -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.W) + self.b\n",
    "\n",
    "# Start with the same eta and tune parameters for SGD\n",
    "sgd_eta = best_eta\n",
    "sgd_iterations = 5000  # Start with more iterations for stochastic updates\n",
    "model_sgd = LinearRegressionSGD(learning_rate=sgd_eta, iterations=sgd_iterations)\n",
    "model_sgd.fit(X, y)\n",
    "\n",
    "# Predict and calculate RMSE\n",
    "y_pred_sgd = model_sgd.predict(X)\n",
    "rmse_sgd = np.sqrt(mean_squared_error(y, y_pred_sgd))\n",
    "print(f\"Step e: RMSE (Stochastic Gradient Descent): {rmse_sgd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8444bcbf-972f-4c18-a9a9-008859b8bd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99, 2),\n",
       "    X  Y\n",
       " 0  1  1\n",
       " 1  0  0\n",
       " 2  0  0\n",
       " 3  1  0\n",
       " 4  1  0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = \"data.csv\"  # Update the path to the uploaded data\n",
    "df = pd.read_csv(data_path)\n",
    "df.shape, df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc052636-fd84-4a80-8fdf-36c78d0ffe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step b: Prior Probabilities:\n",
      "P(x=0): 0.5556, P(x=1): 0.4444, P(y=0): 0.5253, P(y=1): 0.4747\n"
     ]
    }
   ],
   "source": [
    "p_x0 = (df['X'] == 0).mean()\n",
    "p_x1 = (df['X'] == 1).mean()\n",
    "p_y0 = (df['Y'] == 0).mean()\n",
    "p_y1 = (df['Y'] == 1).mean()\n",
    "\n",
    "print(f\"Step b: Prior Probabilities:\\nP(x=0): {p_x0:.4f}, P(x=1): {p_x1:.4f}, P(y=0): {p_y0:.4f}, P(y=1): {p_y1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95ec48fb-1eb8-491f-8e3e-16d792ef66e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step c: Likelihoods:\n",
      "P(x=0|y=0): 0.5769, P(x=1|y=0): 0.4231, P(x=0|y=1): 0.5319, P(x=1|y=1): 0.4681\n"
     ]
    }
   ],
   "source": [
    "# Step c: Calculate likelihoods\n",
    "p_x0_given_y0 = ((df['X'] == 0) & (df['Y'] == 0)).sum() / (df['Y'] == 0).sum()\n",
    "p_x1_given_y0 = ((df['X'] == 1) & (df['Y'] == 0)).sum() / (df['Y'] == 0).sum()\n",
    "p_x0_given_y1 = ((df['X'] == 0) & (df['Y'] == 1)).sum() / (df['Y'] == 1).sum()\n",
    "p_x1_given_y1 = ((df['X'] == 1) & (df['Y'] == 1)).sum() / (df['Y'] == 1).sum()\n",
    "\n",
    "print(f\"Step c: Likelihoods:\\nP(x=0|y=0): {p_x0_given_y0:.4f}, P(x=1|y=0): {p_x1_given_y0:.4f}, P(x=0|y=1): {p_x0_given_y1:.4f}, P(x=1|y=1): {p_x1_given_y1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42d3d2c6-63cf-4fd9-b5d8-1b9ded977758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step d: Posterior Probabilities:\n",
      "P(y=1|x=0): 0.4545, P(y=0|x=0): 0.5455, P(y=1|x=1): 0.5000, P(y=0|x=1): 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Step d: Calculate posterior probabilities\n",
    "p_y1_given_x0 = (p_x0_given_y1 * p_y1) / p_x0\n",
    "p_y0_given_x0 = (p_x0_given_y0 * p_y0) / p_x0\n",
    "p_y1_given_x1 = (p_x1_given_y1 * p_y1) / p_x1\n",
    "p_y0_given_x1 = (p_x1_given_y0 * p_y0) / p_x1\n",
    "\n",
    "print(f\"Step d: Posterior Probabilities:\\nP(y=1|x=0): {p_y1_given_x0:.4f}, P(y=0|x=0): {p_y0_given_x0:.4f}, P(y=1|x=1): {p_y1_given_x1:.4f}, P(y=0|x=1): {p_y0_given_x1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9de49b21-23f0-4261-9430-7fe023238389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step a: Generate the dataset and split into train and test sets\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Generate dataset\n",
    "X, y = datasets.make_blobs(n_samples=100, n_features=4, centers=2, cluster_std=1.5, random_state=123)\n",
    "y = np.array([-1 if i == 0 else 1 for i in y])\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54147c98-21d2-464c-855d-11d3e005d541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step b: Between-class scatter matrix SB:\n",
      " [[ 1.42177386e+00 -1.48370842e+01 -7.83733634e+01 -1.38981884e+01]\n",
      " [-1.48370842e+01  1.54834094e+02  8.17874222e+02  1.45036139e+02]\n",
      " [-7.83733634e+01  8.17874222e+02  4.32022577e+03  7.66118860e+02]\n",
      " [-1.38981884e+01  1.45036139e+02  7.66118860e+02  1.35858203e+02]]\n"
     ]
    }
   ],
   "source": [
    "def compute_sb(X, y):\n",
    "    overall_mean = np.mean(X, axis=0)\n",
    "    classes = np.unique(y)\n",
    "    SB = np.zeros((X.shape[1], X.shape[1]))\n",
    "\n",
    "    for cls in classes:\n",
    "        class_mean = np.mean(X[y == cls], axis=0)\n",
    "        n_cls = X[y == cls].shape[0]\n",
    "        mean_diff = (class_mean - overall_mean).reshape(-1, 1)\n",
    "        SB += n_cls * mean_diff @ mean_diff.T\n",
    "\n",
    "    return SB\n",
    "\n",
    "SB = compute_sb(X_train, y_train)\n",
    "print(\"Step b: Between-class scatter matrix SB:\\n\", SB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a846eedb-85db-4431-8954-453227b27a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step c: Within-class scatter matrix SW:\n",
      " [[184.40393024   6.38328991 -16.01885729   8.00343862]\n",
      " [  6.38328991 198.95383305  -1.96744413   5.73688237]\n",
      " [-16.01885729  -1.96744413 150.76557752   2.51812873]\n",
      " [  8.00343862   5.73688237   2.51812873 144.09650929]]\n",
      "Step c: Inverse of SW:\n",
      " [[ 5.49283896e-03 -1.61524880e-04  5.86666256e-04 -3.08905827e-04]\n",
      " [-1.61524880e-04  5.03753682e-03  5.17913168e-05 -1.92491956e-04]\n",
      " [ 5.86666256e-04  5.17913168e-05  6.69835676e-03 -1.51702444e-04]\n",
      " [-3.08905827e-04 -1.92491956e-04 -1.51702444e-04  6.96726537e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Step c: Compute within-class scatter Sw and its inverse\n",
    "def compute_sw(X, y):\n",
    "    classes = np.unique(y)\n",
    "    SW = np.zeros((X.shape[1], X.shape[1]))\n",
    "\n",
    "    for cls in classes:\n",
    "        class_scatter = np.cov(X[y == cls].T, bias=True) * (X[y == cls].shape[0] - 1)\n",
    "        SW += class_scatter\n",
    "\n",
    "    return SW\n",
    "\n",
    "SW = compute_sw(X_train, y_train)\n",
    "SW_inv = np.linalg.inv(SW)\n",
    "print(\"Step c: Within-class scatter matrix SW:\\n\", SW)\n",
    "print(\"Step c: Inverse of SW:\\n\", SW_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf5e2e86-e588-4cc2-a54e-dcadb8ecdc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step d: Eigenvalues:\n",
      " [3.03906240e+01 5.61892349e-16 5.03934630e-17 0.00000000e+00]\n",
      "Step d: Eigenvectors:\n",
      " [[-0.05876605 -0.16956648  0.3192606  -0.99984555]\n",
      " [-0.14254062 -0.96718363  0.29155143 -0.00250949]\n",
      " [-0.97595821  0.16297647 -0.20511277 -0.01718218]\n",
      " [-0.15405937  0.09613379  0.87806559 -0.00271228]]\n"
     ]
    }
   ],
   "source": [
    "# Step d: Find eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(np.linalg.inv(SW) @ SB)\n",
    "\n",
    "# Sort eigenvalues and eigenvectors by descending order of eigenvalues\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "# Transform the train data to each projection plane\n",
    "projections = [X_train @ eigenvectors[:, i] for i in range(eigenvectors.shape[1])]\n",
    "\n",
    "print(\"Step d: Eigenvalues:\\n\", eigenvalues)\n",
    "print(\"Step d: Eigenvectors:\\n\", eigenvectors)\n",
    "\n",
    "# Choose the most ideal eigenvector (corresponding to the largest eigenvalue)\n",
    "best_eigenvector = eigenvectors[:, 0]\n",
    "best_projection = projections[0]\n",
    "\n",
    "# Explanation: The eigenvector corresponding to the largest eigenvalue captures the most variance\n",
    "# between classes, making it the most ideal for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "739679c7-8423-4055-8995-a40690ec1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step e: Train accuracy using best eigenvector: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Step e: Predict the class of train data using the best eigenvector\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Project train data onto the best eigenvector\n",
    "train_projection = X_train @ best_eigenvector\n",
    "\n",
    "# Predict classes based on the sign of the projection\n",
    "train_predictions = np.sign(train_projection)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print(\"Step e: Train accuracy using best eigenvector:\", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97835dfd-22c8-4458-8435-b570865993b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step f: Train accuracies using other eigenvectors: [0.4625, 0.525, 0.525]\n"
     ]
    }
   ],
   "source": [
    "# Step f: Predict train data classes using other eigenvectors and calculate accuracy\n",
    "other_accuracies = []\n",
    "for i in range(1, eigenvectors.shape[1]):\n",
    "    projection = X_train @ eigenvectors[:, i]\n",
    "    predictions = np.sign(projection)\n",
    "    accuracy = accuracy_score(y_train, predictions)\n",
    "    other_accuracies.append(accuracy)\n",
    "\n",
    "print(\"Step f: Train accuracies using other eigenvectors:\", other_accuracies)\n",
    "\n",
    "# Explanation: The best eigenvector should yield the highest accuracy as it captures the most\n",
    "# discriminative information for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47be97-1bf9-4d27-ba03-55c315855458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
